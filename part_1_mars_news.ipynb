{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 12 Challenge\n",
    "## Deliverable 1: Scrape Titles and Preview Text from Mars News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Splinter and BeautifulSoup\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Visit the Website\n",
    "\n",
    "1. Use automated browsing to visit the [Mars NASA news site](https://redplanetscience.com). Inspect the page to identify which elements to scrape.\n",
    "\n",
    "      > **Hint** To identify which elements to scrape, you might want to inspect the page by using Chrome DevTools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit the Mars NASA news site: https://redplanetscience.com\n",
    "url = 'https://redplanetscience.com/'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Scrape the Website\n",
    "\n",
    "Create a Beautiful Soup object and use it to extract text elements from the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Beautiful Soup object\n",
    "html = browser.html\n",
    "html_soup = soup(html, 'html.parser')\n",
    "#print(html_soup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# Extract all the text elements\n",
    "titles = html_soup.find_all('div', class_='content_title')\n",
    "print(len(titles))\n",
    "previews = html_soup.find_all('div', class_='article_teaser_body')\n",
    "print(len(previews))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Store the Results\n",
    "\n",
    "Extract the titles and preview text of the news articles that you scraped. Store the scraping results in Python data structures as follows:\n",
    "\n",
    "* Store each title-and-preview pair in a Python dictionary. And, give each dictionary two keys: `title` and `preview`. An example is the following:\n",
    "\n",
    "  ```python\n",
    "  {'title': \"Mars Rover Begins Mission!\", \n",
    "        'preview': \"NASA's Mars Rover begins a multiyear mission to collect data about the little-explored planet.\"}\n",
    "  ```\n",
    "\n",
    "* Store all the dictionaries in a Python list.\n",
    "\n",
    "* Print the list in your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the dictionaries\n",
    "result=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the text elements\n",
    "# Extract the title and preview text from the elements\n",
    "# Store each title and preview pair in a dictionary\n",
    "# Add the dictionary to the list\n",
    "for (t, p) in zip( titles, previews):\n",
    "\n",
    "    #print(\"t.text:%s\" % t.text)\n",
    "    #print(\"p.text:%s\" % p.text)\n",
    "    d = {}\n",
    "    d['titles'] = t.text\n",
    "    d['previews'] = p.text\n",
    "    #print(\"d:%s\" % d)\n",
    "    result.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'titles': \"NASA's Mars 2020 Rover Closer to Getting Its Name\", 'previews': \"155 students from across the U.S. have been chosen as semifinalists in NASA's essay contest to name the Mars 2020 rover, and see it launch from Cape Canaveral this July.\"}\n",
      "{'titles': \"NASA's Perseverance Rover Will Look at Mars Through These 'Eyes'\", 'previews': 'A pair of zoomable cameras will help scientists and rover drivers with high-resolution color images.'}\n",
      "{'titles': 'NASA Invites Students to Name Mars 2020 Rover', 'previews': \"Through Nov. 1, K-12 students in the U.S. are encouraged to enter an essay contest to name NASA's next Mars rover.\"}\n",
      "{'titles': \"NASA's MAVEN Observes Martian Night Sky Pulsing in Ultraviolet Light\", 'previews': 'Vast areas of the Martian night sky pulse in ultraviolet light, according to images from NASA’s MAVEN spacecraft. The results are being used to illuminate complex circulation patterns in the Martian atmosphere.'}\n",
      "{'titles': \"NASA's InSight Flexes Its Arm While Its 'Mole' Hits Pause\", 'previews': \"Now that the lander's robotic arm has helped the mole get underground, it will resume science activities that have been on hold.\"}\n",
      "{'titles': \"Air Deliveries Bring NASA's Perseverance Mars Rover Closer to Launch\", 'previews': \"A NASA Wallops Flight Facility cargo plane transported more than two tons of equipment — including the rover's sample collection tubes — to Florida for this summer's liftoff.\"}\n",
      "{'titles': \"NASA's Briefcase-Size MarCO Satellite Picks Up Honors\", 'previews': 'The twin spacecraft, the first of their kind to fly into deep space, earn a Laureate from Aviation Week & Space Technology.'}\n",
      "{'titles': 'Naming a NASA Mars Rover Can Change Your Life', 'previews': 'Want to name the robotic scientist NASA is sending to Mars in 2020? The student who named Curiosity — the rover currently exploring Mars — will tell you this is an opportunity worth taking.'}\n",
      "{'titles': \"5 Hidden Gems Are Riding Aboard NASA's Perseverance Rover\", 'previews': \"The symbols, mottos, and small objects added to the agency's newest Mars rover serve a variety of purposes, from functional to decorative.\"}\n",
      "{'titles': \"NASA's Curiosity Keeps Rolling As Team Operates Rover From Home\", 'previews': 'The team has learned to meet new challenges as they work remotely on the Mars mission.'}\n",
      "{'titles': 'With Mars Methane Mystery Unsolved, Curiosity Serves Scientists a New One: Oxygen', 'previews': 'For the first time in the history of space exploration, scientists have measured the seasonal changes in the gases that fill the air directly above the surface of Gale Crater on Mars. '}\n",
      "{'titles': \"NASA's Mars Helicopter Attached to Mars 2020 Rover \", 'previews': 'The helicopter will be first aircraft to perform flight tests on another planet.'}\n",
      "{'titles': \"InSight's 'Mole' Team Peers into the Pit\", 'previews': 'Efforts to save the heat probe continue.'}\n",
      "{'titles': \"NASA's New Mars Rover Is Ready for Space Lasers\", 'previews': 'Perseverance is one of a few Mars spacecraft carrying laser retroreflectors. The devices could provide new science and safer Mars landings in the future.'}\n",
      "{'titles': 'New Selfie Shows Curiosity, the Mars Chemist', 'previews': 'The NASA rover performed a special chemistry experiment at the location captured in its newest self-portrait.'}\n"
     ]
    }
   ],
   "source": [
    "# Print the list to confirm success\n",
    "for res in result:\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Step 4: Export the Data\n",
    "\n",
    "Optionally, store the scraped data in a file or database (to ease sharing the data with others). To do so, export the scraped data to either a JSON file or a MongoDB database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data to JSON\n",
    "import json\n",
    "#json_string=json.dumps(result)\n",
    "#print(json_string)\n",
    "with open('result.json', 'w') as f:\n",
    "    json.dump(result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data to MongoDB\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
